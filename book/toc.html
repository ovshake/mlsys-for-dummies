<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- sidebar iframe generated using mdBook

        This is a frame, and not included directly in the page, to control the total size of the
        book. The TOC contains an entry for each page, so if each page includes a copy of the TOC,
        the total size of the page becomes O(n**2).

        The frame is only used as a fallback when JS is turned off. When it's on, the sidebar is
        instead added to the main page by `toc.js` instead. The JavaScript mode is better
        because, when running in a `file:///` URL, the iframed page would not be Same-Origin as
        the rest of the page, so the sidebar and the main page theme would fall out of sync.
        -->
        <meta charset="UTF-8">
        <meta name="robots" content="noindex">
        <!-- Custom HTML head -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">
        <!-- Custom theme stylesheets -->
    </head>
    <body class="sidebar-iframe-inner">
        <ol class="chapter"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="introduction.html" target="_parent">Introduction</a></span></li><li class="chapter-item expanded "><li class="spacer"></li></li><li class="chapter-item expanded "><li class="part-title">Part I: Distributed Computing</li></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter01.html" target="_parent"><strong aria-hidden="true">1.</strong> Chapter 1: Your First Distributed Program</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter01-verify.html" target="_parent"><strong aria-hidden="true">1.1.</strong> verify_setup.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter01-hello.html" target="_parent"><strong aria-hidden="true">1.2.</strong> hello_distributed.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter02.html" target="_parent"><strong aria-hidden="true">2.</strong> Chapter 2: Point-to-Point Communication</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter02-send.html" target="_parent"><strong aria-hidden="true">2.1.</strong> send_recv_basic.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter02-pipeline.html" target="_parent"><strong aria-hidden="true">2.2.</strong> pipeline_simulation.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter03.html" target="_parent"><strong aria-hidden="true">3.</strong> Chapter 3: Collective Operations</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter03-cheatsheet.html" target="_parent"><strong aria-hidden="true">3.1.</strong> collective_cheatsheet.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter03-mean.html" target="_parent"><strong aria-hidden="true">3.2.</strong> distributed_mean.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter04.html" target="_parent"><strong aria-hidden="true">4.</strong> Chapter 4: NCCL and GPU Topology</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter04-topology.html" target="_parent"><strong aria-hidden="true">4.1.</strong> topology_inspector.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part1-distributed/chapter04-benchmark.html" target="_parent"><strong aria-hidden="true">4.2.</strong> benchmark_algorithms.py</a></span></li></ol><li class="chapter-item expanded "><li class="spacer"></li></li><li class="chapter-item expanded "><li class="part-title">Part II: Parallelism Strategies</li></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter05.html" target="_parent"><strong aria-hidden="true">5.</strong> Chapter 5: Data Parallelism Deep Dive</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter05-ddp.html" target="_parent"><strong aria-hidden="true">5.1.</strong> simple_ddp.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter05-gradient.html" target="_parent"><strong aria-hidden="true">5.2.</strong> gradient_sync_visualizer.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter06.html" target="_parent"><strong aria-hidden="true">6.</strong> Chapter 6: Tensor Parallelism</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter06-linear.html" target="_parent"><strong aria-hidden="true">6.1.</strong> tp_linear.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter06-mlp.html" target="_parent"><strong aria-hidden="true">6.2.</strong> tp_mlp.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter07.html" target="_parent"><strong aria-hidden="true">7.</strong> Chapter 7: Pipeline &amp; Expert Parallelism</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter07-pipeline.html" target="_parent"><strong aria-hidden="true">7.1.</strong> pipeline_schedule_viz.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part2-parallelism/chapter07-calculator.html" target="_parent"><strong aria-hidden="true">7.2.</strong> parallel_strategy_calculator.py</a></span></li></ol><li class="chapter-item expanded "><li class="spacer"></li></li><li class="chapter-item expanded "><li class="part-title">Part III: LLM Inference Systems</li></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter08.html" target="_parent"><strong aria-hidden="true">8.</strong> Chapter 8: Server Anatomy</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter08-server.html" target="_parent"><strong aria-hidden="true">8.1.</strong> minimal_inference_server.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter09.html" target="_parent"><strong aria-hidden="true">9.</strong> Chapter 9: KV Cache Management</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter09-calculator.html" target="_parent"><strong aria-hidden="true">9.1.</strong> kv_cache_calculator.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter09-prefix.html" target="_parent"><strong aria-hidden="true">9.2.</strong> prefix_sharing_demo.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter10.html" target="_parent"><strong aria-hidden="true">10.</strong> Chapter 10: Scheduling &amp; CUDA Graphs</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter10-cuda.html" target="_parent"><strong aria-hidden="true">10.1.</strong> cuda_graph_simple.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter10-benchmark.html" target="_parent"><strong aria-hidden="true">10.2.</strong> scheduling_overhead_benchmark.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter11.html" target="_parent"><strong aria-hidden="true">11.</strong> Chapter 11: Speculative &amp; Constraint Decoding</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter11-speculative.html" target="_parent"><strong aria-hidden="true">11.1.</strong> speculative_demo.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part3-inference/chapter11-json.html" target="_parent"><strong aria-hidden="true">11.2.</strong> json_constraint_demo.py</a></span></li></ol><li class="chapter-item expanded "><li class="spacer"></li></li><li class="chapter-item expanded "><li class="part-title">Part IV: RLHF Systems</li></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter12.html" target="_parent"><strong aria-hidden="true">12.</strong> Chapter 12: RL Fundamentals for LLMs</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter12-ppo.html" target="_parent"><strong aria-hidden="true">12.1.</strong> ppo_cartpole.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter12-gae.html" target="_parent"><strong aria-hidden="true">12.2.</strong> gae_visualizer.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter13.html" target="_parent"><strong aria-hidden="true">13.</strong> Chapter 13: RLHF Computation Flow</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter13-loop.html" target="_parent"><strong aria-hidden="true">13.1.</strong> rlhf_loop_pseudo.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter13-reward.html" target="_parent"><strong aria-hidden="true">13.2.</strong> reward_calculator.py</a></span></li></ol><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter14.html" target="_parent"><strong aria-hidden="true">14.</strong> Chapter 14: RLHF System Architecture</a></span><ol class="section"><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter14-weight.html" target="_parent"><strong aria-hidden="true">14.1.</strong> weight_update_demo.py</a></span></li><li class="chapter-item expanded "><span class="chapter-link-wrapper"><a href="part4-rlhf/chapter14-memory.html" target="_parent"><strong aria-hidden="true">14.2.</strong> memory_timeline.py</a></span></li></ol></li></ol>
    </body>
</html>
